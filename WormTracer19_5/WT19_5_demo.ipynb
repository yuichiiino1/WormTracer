{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font color='orange'>Please execute all cells except either Option1 or Option 2 below.<br>\n",
        "Depending on your selection of Option1/2, results will be saved either in the temporary folder found in the left pane (option1) or in your google drive folder MyDrive/WormTracer_demo_output (option2). <br>\n",
        "It will take a while to complete saving to the .mp4 and .tif files.</font>"
      ],
      "metadata": {
        "id": "4egzPbMmQ4q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/yuichiiino1/WormTracer.git\n",
        "! unzip '/content/WormTracer/Sample Images/WT_binary_multipage_tiff.zip'"
      ],
      "metadata": {
        "id": "XAjf3FbyIi1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import sys\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "B3PAUVwjM8H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ8E6zWnryBf"
      },
      "outputs": [],
      "source": [
        "# << Option 1 >>\n",
        "# Use this box if you do not mount your google drive and save the results there.\n",
        "\n",
        "output_directory = \"/content/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# << Option 2 (recommended) >>\n",
        "# Use this box if you mount your google drive and save the results there.\n",
        "\n",
        "import google.colab.drive\n",
        "google.colab.drive.mount('gdrive')\n",
        "output_directory = \"/content/gdrive/MyDrive/WormTracer_demo_output\"\n",
        "os.mkdir(output_directory)\n"
      ],
      "metadata": {
        "id": "saMgdVHoNJm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUUW27TPr3HG"
      },
      "outputs": [],
      "source": [
        "### input information and params ###\n",
        "\"\"\"\n",
        "dataset_path (mandatory):\n",
        "Path to a folder including input images.\n",
        "Images are either as a single multipage tiff file or serial numbered image files, with either of the following format.\n",
        "\".bmp\", \".dib\", \".pbm\", \".pgm\", \".ppm\", \".pnm\", \".ras\", \".png\", \".tiff\", \".tif\", \".jp2\", \".jpeg\", \".jpg\", \".jpe\"\n",
        "ALL RESULTS ARE SAVED in dataset_path.\n",
        "\n",
        "output_directory (can be omitted):\n",
        "Path to a directory in which output of WormTracer will be saved in a folder named xxxx_output_n, where xxxx comes from dataset_path name, n is a serial number.\n",
        "If output_directory is not given at all or is an empty string, the folder xxxx_output_n is created at the same level as dataset_path.\n",
        "If the directory output_directory does not exist, a directory is created.\n",
        "\n",
        "functions_path (mandatory):\n",
        "Path to functions.py file, which is essential.\n",
        "\n",
        "local_time_difference:\n",
        "Time difference relative to UTC (hours). Affects time stamps used in result file names.\n",
        "\n",
        "start_T, end_T(int, > 0):\n",
        "You can set frames which are applied to WormTracer.\n",
        "If you want to use all frames, set both start_T and end_T as 0 (assuming the image number starts from 0).\n",
        "\n",
        "rescale(float, > 0, <= 1):\n",
        "You can change the scale of image to use for tracing by this value.\n",
        "If MEMORY ERROR occurs, set this value lower.\n",
        "For example if you set it 0.5, the size of images will be half of the original.\n",
        "Default value is 1.\n",
        "\n",
        "Tscale(int, > 0):\n",
        "You can reduce frames by thinning out the movie by this value.\n",
        "If MEMORY ERROR occurs, set this value higher.\n",
        "For example, if you set it to 2, even-numbered frames will be picked up.\n",
        "This parameter is useful in case frame rate is too high.\n",
        "Default value is 1.\n",
        "\n",
        "continuity_loss_weight(float, > 0):\n",
        "This value is the weight of the continuity constraint.\n",
        "Around 10000 is recommended, but if the object moves fast, set it lower.\n",
        "\n",
        "smoothness_loss_weight(float, > 0):\n",
        "This value is the weight of the smoothness constraint.\n",
        "Around 50000 is recommended, but if the object bends sharply, set it lower.\n",
        "\n",
        "length_loss_weight(float, > 0):\n",
        "This value is the weight of the length continuity constraint.\n",
        "Around 50 is recommended, but if length of the object changes drastically, set it lower.\n",
        "\n",
        "center_loss_weight(float, > 0):\n",
        "This value is the weight of the center position constraint.\n",
        "Around 50 is recommended.\n",
        "\n",
        "plot_n(int, > 1):\n",
        "This value is plot number of center line.\n",
        "Around 100 is recommended.\n",
        "\n",
        "epoch_plus(int, > 0):\n",
        "This value is additional training epoch number.\n",
        "After annealing is finished, training will be performed for at most epoch_plus times.\n",
        "Over 1000 is recommended.\n",
        "\n",
        "speed(float, > 0):\n",
        "This value is speed of annealing progress.\n",
        "The larger this value, the faster the learning is completed.\n",
        "0.1 is efficient, 0.05 is cautious.\n",
        "\n",
        "lr(float, > 0):\n",
        "This value is learning rate of training.\n",
        "Around 0.05 is recommended.\n",
        "\n",
        "body_ratio(float, > 0):\n",
        "This value is body (rigid part of the object) ratio of the object.\n",
        "If the object is a typical worm, set it around 90.\n",
        "\n",
        "judge_head_method (string, 'amplitude' or 'frequency'):\n",
        "Discriminate head and tail by eigher of the following criteria,\n",
        "Variance of body curvature is larger near the head ('amplitude')\n",
        "Frequency of body curvature change is larger near the head ('frequency')\n",
        "\n",
        "num_t(int, > 0):\n",
        "This value means the number of images which are displayed\n",
        "when show_image function is called.\n",
        "Default value is 5.\n",
        "If you want to see all frames, set it to \"np.inf\".\n",
        "\n",
        "ShowProgress (True or False):\n",
        "If True, shows progress during optimization repeats.\n",
        "\n",
        "SaveProgress (True or False):\n",
        "If True, saves worm images during optimization in \"progress_image\" folder created in datafolder.\n",
        "\n",
        "show_progress_freq(int, > 0):\n",
        "This value is epoch frequency of displaying tracing progress.\n",
        "\n",
        "save_progress_freq(int, > 0):\n",
        "This value is epoch frequency of saving tracing progress.\n",
        "\n",
        "save_progress_num(int, > 0):\n",
        "This value is the number of images that are included in saved progress tracing.\n",
        "\n",
        "SaveCenterlinedWormsSerial (True or False):\n",
        "If True, saves input images with estimated centerline as seirial numbered png files in full_line_images folder.\n",
        "\n",
        "SaveCenterlinedWormsMovie (True or False):\n",
        "If True, saves input images with estimated centerline as a movie full_line_images.mp4\n",
        "\n",
        "SaveCenterlinedWormsMultitiff (True or False):\n",
        "If True, saves input images with estimated centerline as a multipage tiff full_line_images.tif\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dataset_path = \"/content/WT_binary.tif\"\n",
        "functions_path = \"/content/WormTracer/WormTracer19_5/WormTracer\"\n",
        "\n",
        "\n",
        "local_time_difference = 9\n",
        "\n",
        "params = {}\n",
        "\n",
        "# parameters\n",
        "params['start_T'] = 0\n",
        "params['end_T'] = 0\n",
        "params['rescale'] = 0.4\n",
        "params['Tscale'] = 1\n",
        "\n",
        "params['continuity_loss_weight'] = 10000\n",
        "params['smoothness_loss_weight'] = 100000\n",
        "params['length_loss_weight'] = 50\n",
        "params['center_loss_weight'] = 50\n",
        "\n",
        "params['plot_n'] = 100\n",
        "params['epoch_plus'] = 1500\n",
        "params['speed'] = 0.05\n",
        "params['lr'] = 0.05\n",
        "params['body_ratio'] = 90\n",
        "#params['judge_head_method'] = 'amplitude'\n",
        "params['judge_head_method'] = 'frequency'\n",
        "\n",
        "params['local_time_difference'] = local_time_difference\n",
        "\n",
        "# display options\n",
        "params['num_t'] = 5\n",
        "params['ShowProgress'] = False\n",
        "params['SaveProgress'] = False\n",
        "params['show_progress_freq'] = 200\n",
        "params['save_progress_freq'] = 50\n",
        "params['save_progress_num'] = 50\n",
        "\n",
        "params['SaveCenterlinedWormsSerial'] = True\n",
        "params['SaveCenterlinedWormsMovie'] = True\n",
        "params['SaveCenterlinedWormsMultitiff'] = True\n",
        "\n",
        "# log\n",
        "time_now = datetime.datetime.now()\n",
        "logs = [f\"Code executed at {time_now}\\n\"]\n",
        "logs.append(f\"Params : {params}\\n\")\n",
        "\n",
        "#### make use of GPU ####\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('Running using GPU.')\n",
        "  logs.append(\"Running using GPU.\\n\\n\")\n",
        "else:\n",
        "  device = 'cpu'\n",
        "  print('Running using CPU. GPU is recommended')\n",
        "  logs.append(\"Running using CPU. GPU is recommended\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrK6a_rwr3Lj"
      },
      "outputs": [],
      "source": [
        "sys.path.append(functions_path)\n",
        "from functions import *\n",
        "from pathlib import Path\n",
        "\n",
        "# set output_path\n",
        "if not 'output_directory' in locals() and not 'output_directory' in globals():\n",
        "    output_directory = ''\n",
        "dataset_name, output_path, output_name = set_output_path(dataset_path, output_directory) # output_path is created in output_directory\n",
        "print('dataset_path =', dataset_path)\n",
        "print('output_path =', output_path)\n",
        "\n",
        "# basic informatin to save\n",
        "params['dataset_path'] = dataset_path\n",
        "params['output_path'] = output_path\n",
        "\n",
        "# read data property(image size, frame number)\n",
        "filenames_all = get_filenames(dataset_path)\n",
        "\n",
        "#filenames_full = filenames_all[:params['end_T']][params['start_T']:] if params['end_T'] else filenames_all[params['start_T']:]\n",
        "#filenames = filenames_full[::params['Tscale']]\n",
        "imshape, Worm_is_black, multi_flag, n_input_images = get_property(filenames_all, params['rescale'])\n",
        "Tscaled_ind = list(range(n_input_images))\n",
        "Tscaled_ind = Tscaled_ind[params['start_T']:params['end_T']+1] if params['end_T'] else Tscaled_ind[params['start_T']:]\n",
        "Tscaled_ind = Tscaled_ind[::params['Tscale']]\n",
        "\n",
        "# read images and get information\n",
        "# getting xy plots by thinning in function ; read_image_and_xy()\n",
        "real_image, x, y, y_st, x_st, unitLength, pre_width = read_image_and_xy(imshape, filenames_all, params['rescale'], params['plot_n'], Worm_is_black, multi_flag, Tscaled_ind)\n",
        "theta = make_theta_from_xy(x, y)\n",
        "print('\\rframe = ', len(Tscaled_ind),' shape = ', real_image.shape, \" unitLength = \", unitLength)\n",
        "\n",
        "# log\n",
        "time_now = datetime.datetime.now()\n",
        "logs.append(f\"Reading images finished at {time_now}\\n\")\n",
        "logs.append(f\"frame = {len(Tscaled_ind)} shape = {real_image.shape} unitLength = {unitLength}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYBk3HNaS3kj"
      },
      "outputs": [],
      "source": [
        "# make worm model image from plots\n",
        "params['alpha'] = pre_width.min()\n",
        "image_info = {'image_shape':real_image.shape, 'device':device}\n",
        "cap_span = calc_cap_span(image_info, params['plot_n'], s_m=8000)\n",
        "model_image = make_image(x, y, x_st, y_st, params, image_info, cap_span)\n",
        "\n",
        "# get points for trace blocks\n",
        "image_losses = np.mean((model_image - real_image)**2, axis=(1,2))\n",
        "image_loss_max = get_image_loss_max(image_losses, real_image, x, y, x_st, y_st, params, image_info, cap_span)\n",
        "use_points, nont_flag, simple_area = get_use_points(image_losses, image_loss_max, cap_span, x, y, params['plot_n'], show_plot=True)\n",
        "\n",
        "show_image(real_image, params['num_t'], title='real image')\n",
        "show_image(model_image, params['num_t'], title='model image')\n",
        "print('use_points \\n',use_points)\n",
        "\n",
        "# log 3\n",
        "time_now = datetime.datetime.now()\n",
        "logs.append(f\"Determining time blocks finished at {time_now}\\n\")\n",
        "logs.append(f\"use_points : {use_points}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE6QgYMM8QJ0"
      },
      "outputs": [],
      "source": [
        "losses_all = []; shape_params = [];\n",
        "unitLength = prepare_for_train(pre_width, simple_area, x, y, params)\n",
        "if params['SaveProgress']:\n",
        "  clear_dir(output_path, output_name+'_progress_image')\n",
        "logs.append(\"STEP1 : optimization for simple posture blocks\\n\\n\")\n",
        "\n",
        "# main loop 1\n",
        "for i in range(len(use_points)-1):\n",
        "  if nont_flag[i]:\n",
        "    losses_all.append(0)\n",
        "    continue\n",
        "  use_area = (use_points[i], use_points[i+1])\n",
        "  print(use_area[0], \":\", use_area[1])\n",
        "  params['use_area'] = use_area\n",
        "  #filenames_ = filenames[use_area[0]:use_area[1]+1]\n",
        "  T = use_area[1] - use_area[0] + 1\n",
        "  theta_ = theta[use_area[0]:use_area[1]+1,:].copy()\n",
        "\n",
        "  # read and preprocess images\n",
        "  real_image, y_st, x_st = read_image(imshape, filenames_all, params['rescale'], Worm_is_black, multi_flag, Tscaled_ind[use_area[0]:use_area[1]+1])\n",
        "  show_image(real_image, params['num_t'], title='real image', use_area=use_area)\n",
        "  save_progress(real_image, output_path, output_name, params, txt='real')\n",
        "  image_info['image_shape'] = real_image.shape\n",
        "\n",
        "  # set init value\n",
        "  theta_cand, _ = make_thetaCand(theta_)\n",
        "  theta_[-1,:] = theta_cand[0]\n",
        "  init_cx, init_cy = set_init_xy(real_image)\n",
        "  init_theta = torch.tensor(theta_)\n",
        "  init_unitLength = torch.ones(T, dtype=torch.float)*unitLength\n",
        "  init_data = [init_cx, init_cy, unitLength]\n",
        "\n",
        "  #print(real_image.shape)\n",
        "  #print(init_cx.shape)\n",
        "  #print(init_theta.shape)\n",
        "  #print(init_unitLength.shape)\n",
        "  #print(image_info['image_shape'])\n",
        "\n",
        "\n",
        "  # make model instance and training\n",
        "  model = Model(init_cx, init_cy, init_theta, init_unitLength, image_info, params).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "  params['id'] = 0\n",
        "  losses = train3(model, real_image, optimizer, params, device, init_data, output_path, output_name, is_nont=False)\n",
        "\n",
        "  # get trace information\n",
        "  losses_all.append(losses)\n",
        "  theta_model = model.theta.detach().cpu().numpy()\n",
        "  unitL_model = model.unitLength.detach().cpu().numpy().reshape(-1,1)\n",
        "  x_cent, y_cent = model.cx.detach().cpu().numpy(), model.cy.detach().cpu().numpy()\n",
        "  shape_params.append((T, model.alpha.detach().cpu(), model.gamma.detach().cpu(), model.delta.detach().cpu()))\n",
        "  model_image = model()\n",
        "  show_image(model_image, params['num_t'], title='model image', use_area=use_area)\n",
        "  show_loss_plot(losses_all[-1], title='losses of model', use_area=use_area)\n",
        "\n",
        "  # reconstruct plots from model results\n",
        "  x_model, y_model = make_plot(theta_model, unitL_model, x_cent, y_cent)\n",
        "  x[use_area[0]:use_area[1]+1,:] = x_model + x_st\n",
        "  y[use_area[0]:use_area[1]+1,:] = y_model + y_st\n",
        "\n",
        "  # log\n",
        "  logs.append(str(use_area)+\"\\n\")\n",
        "  logs.append(f\"image loss : {np.mean(losses[0])}\\n\")\n",
        "  logs.append(f\"continuity loss : {np.mean(losses[1])}\\n\")\n",
        "  logs.append(f\"smoothing loss : {np.mean(losses[2])}\\n\")\n",
        "  logs.append(f\"length loss : {np.mean(losses[3])}\\n\")\n",
        "  logs.append(f\"center loss : {np.mean(losses[4])}\\n\\n\")\n",
        "time_now = datetime.datetime.now()\n",
        "logs.append(f\"STEP1 finished at {time_now}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iwCcWWVse7V"
      },
      "outputs": [],
      "source": [
        "params['init_alpha'], params['init_gamma'], params['init_delta'] = get_shape_params(shape_params, params)\n",
        "logs.append(\"STEP2 : optimization for complex posture blocks\\n\\n\")\n",
        "\n",
        "# main loop 2\n",
        "for i in range(len(use_points)-1):\n",
        "  if not nont_flag[i]:\n",
        "    continue\n",
        "  use_area = (use_points[i], use_points[i+1])\n",
        "  print(use_area[0], \":\", use_area[1])\n",
        "  params['use_area'] = use_area\n",
        "  #filenames_ = filenames[use_area[0]:use_area[1]+1]\n",
        "  T = use_area[1] - use_area[0] + 1\n",
        "  theta_ = theta[use_area[0]:use_area[1]+1,:].copy()\n",
        "\n",
        "  # read and preprocess images\n",
        "  #real_image, y_st, x_st = read_image(imshape, filenames_, params['rescale'], Worm_is_black)\n",
        "  real_image, y_st, x_st = read_image(imshape, filenames_all, params['rescale'], Worm_is_black, multi_flag, Tscaled_ind[use_area[0]:use_area[1]+1])\n",
        "  show_image(real_image, params['num_t'], title='real image', use_area=use_area)\n",
        "  save_progress(real_image, output_path, output_name, params, txt='real')\n",
        "  image_info['image_shape'] = real_image.shape\n",
        "\n",
        "  # make flipping theta candidate\n",
        "  theta_cand, _ = make_thetaCand(theta_)\n",
        "\n",
        "  # set init value\n",
        "  init_cx, init_cy = set_init_xy(real_image)\n",
        "  init_theta = torch.from_numpy(np.linspace(theta_[0,:], theta_cand[0], T))\n",
        "  init_unitLength = torch.ones(T, dtype=torch.float)*unitLength\n",
        "  init_data = [init_cx, init_cy, unitLength]\n",
        "\n",
        "  # make model instance and training\n",
        "  model = Model(init_cx, init_cy, init_theta, init_unitLength, image_info, params).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "  params['id'] = 0\n",
        "  losses_all[i] = train3(model, real_image, optimizer, params, device, init_data, output_path, output_name)\n",
        "\n",
        "  # get trace information\n",
        "  theta_model = model.theta.detach().cpu().numpy()\n",
        "  unitL_model = model.unitLength.detach().cpu().numpy().reshape(-1,1)\n",
        "  x_cent, y_cent = model.cx.detach().cpu().numpy(), model.cy.detach().cpu().numpy()\n",
        "  model_image = model()\n",
        "\n",
        "  # flip final theta to trace again\n",
        "  init_theta = torch.from_numpy(np.linspace(theta_[0,:], theta_cand[1], T))\n",
        "\n",
        "  # make model instance and training\n",
        "  model = Model(init_cx, init_cy, init_theta, init_unitLength, image_info, params).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "  params['id'] = 1\n",
        "  losses = train3(model, real_image, optimizer, params, device, init_data, output_path, output_name)\n",
        "\n",
        "  # get trace information if loss is smaller\n",
        "  select_ind = loss_compair([losses_all[i], losses])\n",
        "  if select_ind:\n",
        "    theta_model = model.theta.detach().cpu().numpy()\n",
        "    unitL_model = model.unitLength.detach().cpu().numpy().reshape(-1,1)\n",
        "    x_cent, y_cent = model.cx.detach().cpu().numpy(), model.cy.detach().cpu().numpy()\n",
        "    model_image = model()\n",
        "    losses_all[i] = losses\n",
        "  remove_progress(output_path, '{}-{}_id{}*.png'.format(use_area[0], use_area[1], 1-select_ind))\n",
        "\n",
        "  # reconstruct plots from model results\n",
        "  x_model, y_model = make_plot(theta_model, unitL_model, x_cent, y_cent)\n",
        "  show_image(model_image, params['num_t'], title='model image', use_area=use_area)\n",
        "  show_loss_plot(losses_all[i], title='losses of model{}'.format(select_ind), use_area=use_area)\n",
        "  x[use_area[0]:use_area[1]+1,:] = x_model + x_st\n",
        "  y[use_area[0]:use_area[1]+1,:] = y_model + y_st\n",
        "\n",
        "  # log\n",
        "  logs.append(str(use_area)+\"\\n\")\n",
        "  logs.append(f\"image loss : {np.mean(losses[0])}\\n\")\n",
        "  logs.append(f\"continuity loss : {np.mean(losses[1])}\\n\")\n",
        "  logs.append(f\"smoothing loss : {np.mean(losses[2])}\\n\")\n",
        "  logs.append(f\"length loss : {np.mean(losses[3])}\\n\")\n",
        "  logs.append(f\"center loss : {np.mean(losses[4])}\\n\\n\")\n",
        "\n",
        "time_now = datetime.datetime.now()\n",
        "logs.append(f\"STEP2 finished at {time_now}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnrsmBBzse9a"
      },
      "outputs": [],
      "source": [
        "# revise areas which have too large loss\n",
        "losslarge_area = find_losslarge_area(losses_all)\n",
        "logs.append(\"STEP3 :　re-optimization for unsuccessful blocks with complex postures\\n\\n\")\n",
        "\n",
        "for i in range(len(use_points)-1):\n",
        "  if losslarge_area[i] and nont_flag[i]:\n",
        "    use_area = (use_points[i], use_points[i+1])\n",
        "    print(use_area[0], \":\", use_area[1], \" too large loss! \")\n",
        "    params['use_area'] = use_area\n",
        "    #filenames_ = filenames[use_area[0]:use_area[1]+1]\n",
        "    T = use_area[1] - use_area[0] + 1\n",
        "    theta_ = theta[use_area[0]:use_area[1]+1,:].copy()\n",
        "\n",
        "    # read and preprocess images\n",
        "    #real_image, y_st, x_st = read_image(imshape, filenames_, params['rescale'], Worm_is_black)\n",
        "    real_image, y_st, x_st = read_image(imshape, filenames_all, params['rescale'], Worm_is_black, multi_flag, Tscaled_ind[use_area[0]:use_area[1]+1])\n",
        "    show_image(real_image, params['num_t'], title='real image')\n",
        "    image_info['image_shape'] = real_image.shape\n",
        "\n",
        "    # make flipping candidate\n",
        "    _, theta_cand = make_thetaCand(theta_)\n",
        "\n",
        "    # set init value\n",
        "    init_cx, init_cy = set_init_xy(real_image)\n",
        "    init_theta = torch.from_numpy(np.linspace(theta_[0,:], theta_cand[0], T))\n",
        "    init_unitLength = torch.ones(T, dtype=torch.float)*unitLength\n",
        "    init_data = [init_cx, init_cy, unitLength]\n",
        "\n",
        "    # make model instance and training\n",
        "    update = 0\n",
        "    model = Model(init_cx, init_cy, init_theta, init_unitLength, image_info, params).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "    params['id'] = 2\n",
        "    losses = train3(model, real_image, optimizer, params, device, init_data, output_path, output_name)\n",
        "\n",
        "    # get trace information if loss is smaller\n",
        "    if loss_compair([losses_all[i], losses]):\n",
        "      print(\"update\")\n",
        "      update = 2\n",
        "      theta_model = model.theta.detach().cpu().numpy()\n",
        "      unitL_model = model.unitLength.detach().cpu().numpy().reshape(-1,1)\n",
        "      x_cent, y_cent = model.cx.detach().cpu().numpy(), model.cy.detach().cpu().numpy()\n",
        "      model_image = model()\n",
        "      losses_all[i] = losses\n",
        "      remove_progress(output_path, '{}-{}_id[0-1]*.png'.format(use_area[0], use_area[1]))\n",
        "    else:\n",
        "      print(\"no update\")\n",
        "      remove_progress(output_path, '{}-{}_id2*.png'.format(use_area[0], use_area[1]))\n",
        "\n",
        "    # flip final theta and trace again\n",
        "    init_theta = torch.from_numpy(np.linspace(theta_[0,:], theta_cand[1], T))\n",
        "\n",
        "    # make model instance and training\n",
        "    model = Model(init_cx, init_cy, init_theta, init_unitLength, image_info, params).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "    params['id'] = 3\n",
        "    losses = train3(model, real_image, optimizer, params, device, init_data, output_path, output_name)\n",
        "\n",
        "    # get trace information if loss is smaller\n",
        "    if loss_compair([losses_all[i], losses]):\n",
        "      print(\"update\")\n",
        "      update = 3\n",
        "      theta_model = model.theta.detach().cpu().numpy()\n",
        "      unitL_model = model.unitLength.detach().cpu().numpy().reshape(-1,1)\n",
        "      x_cent, y_cent = model.cx.detach().cpu().numpy(), model.cy.detach().cpu().numpy()\n",
        "      model_image = model()\n",
        "      losses_all[i] = losses\n",
        "      remove_progress(output_path, '{}-{}_id[0-2]*.png'.format(use_area[0], use_area[1]))\n",
        "    else:\n",
        "      print(\"no update\")\n",
        "      remove_progress(output_path, '{}-{}_id3*.png'.format(use_area[0], use_area[1]))\n",
        "\n",
        "    if update:\n",
        "      x_model, y_model = make_plot(theta_model, unitL_model, x_cent, y_cent)\n",
        "      show_image(model_image, params['num_t'], title='model image')\n",
        "      show_loss_plot(losses_all[i], title='losses of new model')\n",
        "\n",
        "      # reconstruct plots from model results\n",
        "      x[use_area[0]:use_area[1]+1,:] = x_model + x_st\n",
        "      y[use_area[0]:use_area[1]+1,:] = y_model + y_st\n",
        "\n",
        "      # log\n",
        "      logs.append(str(use_area)+\" updated\\n\")\n",
        "      logs.append(f\"image loss : {np.mean(losses_all[i][0])}\\n\")\n",
        "      logs.append(f\"continuity loss : {np.mean(losses_all[i][1])}\\n\")\n",
        "      logs.append(f\"smoothing loss : {np.mean(losses_all[i][2])}\\n\")\n",
        "      logs.append(f\"length loss : {np.mean(losses_all[i][3])}\\n\")\n",
        "      logs.append(f\"center loss : {np.mean(losses_all[i][4])}\\n\\n\")\n",
        "\n",
        "time_now = datetime.datetime.now()\n",
        "logs.append(f\"STEP3 finished at {time_now}\\n\\n\")\n",
        "\n",
        "### report final loss ###\n",
        "\n",
        "losses_all_combined = [[],[],[],[],[]]\n",
        "for i in range(len(losses_all)):\n",
        "  losses_all_combined[0] = np.concatenate((losses_all_combined[0],losses_all[i][0]))\n",
        "  losses_all_combined[1] = np.concatenate((losses_all_combined[1],losses_all[i][1], np.ones(1)*np.nan))\n",
        "  losses_all_combined[2] = np.concatenate((losses_all_combined[2],losses_all[i][2]))\n",
        "  losses_all_combined[3] = np.concatenate((losses_all_combined[3],losses_all[i][3], np.ones(1)*np.nan))\n",
        "  losses_all_combined[4] = np.concatenate((losses_all_combined[4],losses_all[i][4]))\n",
        "\n",
        "np.savetxt(os.path.join(output_path, output_name+'_losses.csv'), np.array(losses_all_combined).T, delimiter=',', fmt='%f', comments='' ¥\n",
        "          , header='image_loss,continuity_loss,smoothing_loss,length_loss,center_loss')\n",
        "\n",
        "losses_all_combined[1] = losses_all_combined[1][:-1]\n",
        "losses_all_combined[3] = losses_all_combined[3][:-1]\n",
        "show_loss_plot(losses_all_combined, title='full length losses of model', figsize=(12.8, 4.8), savefigpath=os.path.join(output_path, output_name+'_loss_plot.png'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeZGfFN2se_d"
      },
      "outputs": [],
      "source": [
        "# save params and plots\n",
        "params_for_save = params.copy()\n",
        "for key, value in params_for_save.items():\n",
        "  if torch.is_tensor(value):\n",
        "    params_for_save[key] = params_for_save[key].item()\n",
        "del params_for_save['use_area']\n",
        "\n",
        "# check flipping\n",
        "x, y = flip_check(x, y)\n",
        "\n",
        "# check which side is head or tail\n",
        "if not 'judge_head_method' in params.keys() or params['judge_head_method'] == 'amplitude':\n",
        "    x, y, x_rev, y_rev = judge_head_amplitude(x, y)\n",
        "elif params['judge_head_method'] == 'frequency':\n",
        "    x, y, x_rev, y_rev = judge_head_frequency(x, y)\n",
        "\n",
        "# cancel reduction\n",
        "#T_read_all = params['end_T'] - params['start_T'] if params['end_T'] else len(filenames_all) - params['start_T']\n",
        "#x, y = cancel_reduction(x, y, T_read_all, len(filenames), params['plot_n'])\n",
        "#x, y = cancel_reduction(x, y, n_input_images, len(Tscaled_ind), params['plot_n'])\n",
        "x, y = cancel_reduction(x, y, n_input_images, params['start_T'], params['end_T'], Tscaled_ind, params['plot_n'])\n",
        "\n",
        "#x_rev, y_rev = cancel_reduction(x_rev, y_rev, T_read_all, len(filenames), params['plot_n'])\n",
        "x_rev, y_rev = cancel_reduction(x_rev, y_rev, n_input_images, params['start_T'], params['end_T'], Tscaled_ind, params['plot_n'])\n",
        "\n",
        "tz = datetime.timezone(datetime.timedelta(hours=params['local_time_difference']))\n",
        "time_now = datetime.datetime.now(tz).strftime('%Y-%m-%d_%H:%M:%S.%f')\n",
        "#if not os.path.isdir(os.path.join(output_path, 'results')):\n",
        "#  os.mkdir(os.path.join(output_path, 'results'))\n",
        "with open(os.path.join(output_path, output_name+'_params.json'), \"w\") as f:\n",
        "  json.dump(params_for_save, f)\n",
        "with open(os.path.join(output_path, output_name+'_params.yaml'), \"w\") as f:\n",
        "    yaml.safe_dump(params_for_save, f, sort_keys=False)\n",
        "np.savetxt(os.path.join(output_path, output_name+'_x.csv'), x/params['rescale'], delimiter=',')\n",
        "np.savetxt(os.path.join(output_path, output_name+'_y.csv'), y/params['rescale'], delimiter=',')\n",
        "np.savetxt(os.path.join(output_path, output_name+'_x_rev.csv'), x_rev/params['rescale'], delimiter=',')\n",
        "np.savetxt(os.path.join(output_path, output_name+'_y_rev.csv'), y_rev/params['rescale'], delimiter=',')\n",
        "logs.append(\"Params and plots are successfully saved.\\n\\n\")\n",
        "\n",
        "# save log\n",
        "#if not os.path.isdir(os.path.join(output_path, 'logs')):\n",
        "#  os.mkdir(os.path.join(output_path, 'logs'))\n",
        "with open(os.path.join(output_path, f'{output_name}_log.txt'), mode='w') as f:\n",
        "  for log in logs:\n",
        "    f.write(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4tP2p2asfDY"
      },
      "outputs": [],
      "source": [
        "# save full of real_image and centerline as png images\n",
        "#real_image, y_st, x_st = read_image(imshape, filenames_full, params['rescale'], Worm_is_black)\n",
        "real_image, y_st, x_st = read_image(imshape, filenames_all, params['rescale'], Worm_is_black, multi_flag, list(range(n_input_images)))\n",
        "\n",
        "if params['SaveCenterlinedWormsSerial']:\n",
        "    clear_dir(output_path, output_name+'_png')\n",
        "    #for t in range(len(filenames_full)):\n",
        "    end_T = n_input_images-1 if params['end_T']==0 else params['end_T']\n",
        "    fig, ax = plt.subplots()\n",
        "    for i, t in enumerate( range(params['start_T'], end_T+1) ):\n",
        "        filename = os.path.join(output_path, output_name+'_png', 'image'+str(t).zfill(len(str(n_input_images)))+'.png')\n",
        "        ax.imshow(real_image[t], cmap='gray')\n",
        "        ax.plot(x[i]-x_st, y[i]-y_st, c=\"r\", lw=3)\n",
        "        plt.savefig(filename)\n",
        "        plt.cla()\n",
        "    plt.close()\n",
        "    print('\\npng images saved to ' + filename + ' etc.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xav8RbfcsfFO"
      },
      "outputs": [],
      "source": [
        "# save full of real_image and centerline as mp4 movie\n",
        "if params['SaveCenterlinedWormsMovie']:\n",
        "    fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    ims = []\n",
        "    #for t in range(n_input_images):\n",
        "    end_T = n_input_images-1 if params['end_T']==0 else params['end_T']\n",
        "    for i, t in enumerate( range(params['start_T'], end_T+1) ):\n",
        "        if i%100==0:\n",
        "            print(t, end=' ')\n",
        "        lines = []\n",
        "        lines.extend(ax.plot(x[i]-x_st, y[i]-y_st, c=\"r\", lw=3))\n",
        "        lines.extend([ax.imshow(real_image[t], cmap='gray')])\n",
        "        title = ax.text(0.5, 1.01, 'index: '+str(t), ha='center', va='bottom', transform=ax.transAxes, fontsize='large', color='black')\n",
        "        ims.append(lines+[title])\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50)\n",
        "    rc('animation', html='jshtml')\n",
        "    plt.close()\n",
        "    ################# ani\n",
        "    filename = os.path.join(output_path, output_name+'.mp4')\n",
        "    ani.save(filename)\n",
        "    print('\\nMovie saved to '+ filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlZ-AXoiE29t"
      },
      "outputs": [],
      "source": [
        "# save full of real_image and centerline as multipage tiff\n",
        "if params['SaveCenterlinedWormsMultitiff']:\n",
        "    filename = os.path.join(output_path, output_name+'.tif')\n",
        "    stack = []\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    end_T = n_input_images-1 if params['end_T']==0 else params['end_T']\n",
        "    for i, t in enumerate( range(params['start_T'], end_T+1) ):\n",
        "        if i%100==0:\n",
        "            print(t, end=' ')\n",
        "        ax.imshow(real_image[t], cmap='gray')\n",
        "        ax.plot(x[i]-x_st, y[i]-y_st, c=\"r\", lw=3)\n",
        "        plt.title('index: '+str(t))\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\")\n",
        "        plt.cla()\n",
        "        buf.seek(0)\n",
        "        img2=Image.open(buf).convert('RGB')\n",
        "        stack.append(img2)\n",
        "    stack[0].save(filename, compression=\"tiff_deflate\", save_all=True, append_images=stack[1:])\n",
        "    plt.close(fig)\n",
        "    print('\\nMultipage tiff saved to '+ filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save full of real_image and centerline as multipage tiff\n",
        "if params['SaveCenterlinedWormsMultitiff']:\n",
        "    filename = os.path.join(output_path, output_name+'test.tif')\n",
        "    stack = []\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    end_T = n_input_images-1 if params['end_T']==0 else params['end_T']\n",
        "    for i, t in enumerate( range(10) ):\n",
        "        if i%100==0:\n",
        "            print(t, end=' ')\n",
        "        ax.imshow(real_image[t], cmap='gray')\n",
        "        ax.plot(x[i]-x_st, y[i]-y_st, c=\"r\", lw=3)\n",
        "        plt.title('index: '+str(t))\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\")\n",
        "        plt.cla()\n",
        "        buf.seek(0)\n",
        "        img2=Image.open(buf).convert('RGB')\n",
        "        stack.append(img2)\n",
        "    stack[0].save(filename, compression=\"tiff_deflate\", save_all=True, append_images=stack[1:])\n",
        "    plt.close(fig)\n",
        "    print('\\nMultipage tiff saved to '+ filename)"
      ],
      "metadata": {
        "id": "15mR7VtCgycW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
